import numpy as np
from aenum import extend_enum

from lighteval.metrics.metrics import Metrics, SampleLevelMetric
from lighteval.metrics.utils.metric_utils import MetricCategory, MetricUseCase
from lighteval.tasks.default_prompts import LETTER_INDICES
from lighteval.tasks.lighteval_task import LightevalTaskConfig
from lighteval.tasks.requests import Doc

def prompt_fn(line, task_name: str = None):
    # must subset string to prevent OOM errors
    return Doc(task_name=task_name, query=line["text"][:4096], gold_index=None, choices=None)

TASKS_TABLE = [
    LightevalTaskConfig(
        name="tinystories",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="roneneldan/TinyStories",
        hf_subset="default",
        hf_avail_splits=["train", "validation"],
        evaluation_splits=["validation"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:arxiv",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="arxiv",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:bibliotik",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="bibliotik",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:commoncrawl",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="commoncrawl",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:dm_mathematics",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="dm_mathematics",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:enron",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="enron",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:europarl",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="europarl",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:freelaw",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="freelaw",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:github",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="github",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:gutenberg",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="gutenberg",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:hackernews",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="hackernews",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:nih_exporter",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="nih_exporter",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:opensubtitles",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="opensubtitles",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:openwebtext2",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="openwebtext2",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:pubmed_abstracts",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="pubmed_abstracts",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:pubmed_central",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="pubmed_central",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:stackexchange",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="stackexchange",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:uspto",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="uspto",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:wikipedia",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="wikipedia",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
    LightevalTaskConfig(
        name="pile:youtubesubtitles",
        suite=["community"],
        prompt_function=prompt_fn,
        hf_repo="lighteval/pile_helm",
        hf_subset="youtubesubtitles",
        hf_avail_splits=["test"],
        evaluation_splits=["test"],
        few_shots_split=None,
        few_shots_select=None,
        generation_size=-1,
        stop_sequence=["\n"],
        metric=[Metrics.word_perplexity, Metrics.bits_per_byte],
        trust_dataset=True
    ),
]