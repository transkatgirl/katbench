# katbench
what i use to compare LLM base models

## setup

you will need:

- a working [TGI server](https://huggingface.co/docs/text-generation-inference/en/index)
- lighteval w/ TGI and math support
	- note: due to a [bug in lighteval](https://github.com/huggingface/lighteval/pull/502), you will need to install the transkatgirl/lighteval fork

## usage

first, run the `run.sh` file. this will create the `model.yaml` and `tasks.txt` files before returning an error.

update the `model.yaml` file with your TGI server endpoint, and update the `tasks.txt` file if you wish to change the list of tasks to run. then, run the `run.sh` file to begin the benchmark.

warning: due to a bug in lighteval, results produced by the scripts in this repo cannot be directly compared with those generated by other benchmarking tools